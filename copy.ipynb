{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8557ebae",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 5.477404,
     "end_time": "2023-01-09T16:27:08.307096",
     "exception": false,
     "start_time": "2023-01-09T16:27:02.829692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfl\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import math\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imread\n",
    "import scipy\n",
    "# import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "train_path = 'Train'\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "807e362b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import  MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1a0ef8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5642afa5",
   "metadata": {
    "papermill": {
     "duration": 0.004151,
     "end_time": "2023-01-09T16:27:08.315432",
     "exception": false,
     "start_time": "2023-01-09T16:27:08.311281",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " In 'Train' folder directories are created by class numbers based.\n",
    " Train/class_num/class_num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af8e7c6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T16:27:08.325286Z",
     "iopub.status.busy": "2023-01-09T16:27:08.324712Z",
     "iopub.status.idle": "2023-01-09T16:27:20.449235Z",
     "shell.execute_reply": "2023-01-09T16:27:20.448222Z"
    },
    "papermill": {
     "duration": 12.131676,
     "end_time": "2023-01-09T16:27:20.451314",
     "exception": false,
     "start_time": "2023-01-09T16:27:08.319638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 43 artists>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABMIAAAI/CAYAAACVq3VdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAni0lEQVR4nO3dfZBld1kn8O9jGhAQSTAhIgk2akDRWhFjwBUViQtJxiLgIkK5Enmp7CJZgXV3bXVLVIqqUVbZZUuxUAJBkRflLTpRiPiCbslLgiEkJMAIgyRCAqKgSykCv/3jnoFmmO6ZTJ/bPT3P51PV1bfPvf085/S993dvf+/vnFNjjAAAAADAie5LdnoFAAAAAGA7CMIAAAAAaEEQBgAAAEALgjAAAAAAWhCEAQAAANCCIAwAAACAFlZ2egU2c+qpp47V1dWdXg0AAAAAdomrr776o2OM0w533XEdhK2uruaqq67a6dUAAAAAYJeoqg9sdJ1dIwEAAABoQRAGAAAAQAuCMAAAAABaEIQBAAAA0IIgDAAAAIAWBGEAAAAAtCAIAwAAAKAFQRgAAAAALQjCAAAAAGhBEAYAAABAC4IwAAAAAFoQhAEAAADQgiAMAAAAgBYEYQAAAAC0IAgDAAAAoAVBGAAAAAAtCMIAAAAAaEEQBgAAAEALgjAAAAAAWhCEAQAAANCCIAwAAACAFgRhAAAAALQgCAMAAACgBUEYAAAAAC2s7PQKAHD8WV3bN2u9A3v3zFoPAADgWJgRBgAAAEALgjAAAAAAWhCEAQAAANCCIAwAAACAFgRhAAAAALQgCAMAAACghZWdXgGWY3Vt36z1DuzdM2s9AAAAgO1mRhgAAAAALQjCAAAAAGhBEAYAAABAC4IwAAAAAFoQhAEAAADQgiAMAAAAgBYEYQAAAAC0IAgDAAAAoAVBGAAAAAAtCMIAAAAAaEEQBgAAAEALgjAAAAAAWhCEAQAAANDCyk6vAJzoVtf2zVrvwN49s9YDAACALswIAwAAAKAFQRgAAAAALQjCAAAAAGhBEAYAAABAC4IwAAAAAFoQhAEAAADQgiAMAAAAgBYEYQAAAAC0IAgDAAAAoAVBGAAAAAAtCMIAAAAAaEEQBgAAAEALgjAAAAAAWljZ6RWAnbS6tm/Wegf27pm1HgAAADAfM8IAAAAAaEEQBgAAAEALgjAAAAAAWhCEAQAAANCCIAwAAACAFgRhAAAAALSwstMrAAAAwHxW1/bNWu/A3j2z1gPYSWaEAQAAANCCIAwAAACAFgRhAAAAALQgCAMAAACgBUEYAAAAAC0IwgAAAABoQRAGAAAAQAuCMAAAAABaEIQBAAAA0IIgDAAAAIAWBGEAAAAAtHDEIKyqzqyqP6mqd1XV9VX1tGn53arqyqp67/T9lGl5VdXzqmp/VV1bVQ9YV+ui6fbvraqLlrdZAAAAAPCFVo7iNp9O8uNjjLdX1V2SXF1VVyb5kSRvHGPsraq1JGtJfiLJ+UnOmr4emOT5SR5YVXdL8swkZycZU53Lxxh/P/dGsXyra/tmrXdg755Z6wEAAAAc6ogzwsYYHxpjvH26/I9JbkhyzyQXJrlsutllSR45Xb4wyUvGwpuTnFxV90jy8CRXjjE+NoVfVyY5b86NAQAAAICN3KZjhFXVapJvSfKWJKePMT40XfXhJKdPl++Z5IPrfu2madlGywEAAABg6Y46CKuqL0vyqiRPH2N8Yv11Y4yRxe6OW1ZVF1fVVVV11Uc+8pE5SgIAAADA0QVhVXW7LEKwl44xXj0tvmXa5THT91un5TcnOXPdr58xLdto+RcYY7xgjHH2GOPs00477bZsCwAAAABs6GjOGllJXpjkhjHGL6+76vIkB8/8eFGS161b/vjp7JEPSvLxaRfK1yd5WFWdMp1h8mHTMgAAAABYuqM5a+R3JPnhJO+sqmumZT+VZG+SV1bVk5J8IMljpuuuSHJBkv1JPpnkCUkyxvhYVT0rydum2/38GONjc2wEAAAAABzJEYOwMcZfJKkNrj73MLcfSZ66Qa1Lk1x6W1YQAACAflbX9s1a78DePbPWA3an23TWSAAAAADYrQRhAAAAALQgCAMAAACgBUEYAAAAAC0IwgAAAABoQRAGAAAAQAuCMAAAAABaEIQBAAAA0IIgDAAAAIAWBGEAAAAAtCAIAwAAAKAFQRgAAAAALQjCAAAAAGhBEAYAAABAC4IwAAAAAFoQhAEAAADQgiAMAAAAgBYEYQAAAAC0IAgDAAAAoAVBGAAAAAAtCMIAAAAAaEEQBgAAAEALgjAAAAAAWhCEAQAAANCCIAwAAACAFgRhAAAAALQgCAMAAACghZWdXgEAAADg+La6tm+2Wgf27pmtFtxWZoQBAAAA0IIgDAAAAIAWBGEAAAAAtCAIAwAAAKAFQRgAAAAALQjCAAAAAGhBEAYAAABAC4IwAAAAAFoQhAEAAADQgiAMAAAAgBYEYQAAAAC0IAgDAAAAoAVBGAAAAAAtCMIAAAAAaEEQBgAAAEALgjAAAAAAWhCEAQAAANCCIAwAAACAFgRhAAAAALQgCAMAAACgBUEYAAAAAC0IwgAAAABoQRAGAAAAQAuCMAAAAABaEIQBAAAA0IIgDAAAAIAWBGEAAAAAtCAIAwAAAKAFQRgAAAAALQjCAAAAAGhBEAYAAABAC4IwAAAAAFoQhAEAAADQgiAMAAAAgBYEYQAAAAC0IAgDAAAAoAVBGAAAAAAtCMIAAAAAaEEQBgAAAEALgjAAAAAAWhCEAQAAANCCIAwAAACAFgRhAAAAALQgCAMAAACgBUEYAAAAAC0IwgAAAABoQRAGAAAAQAuCMAAAAABaEIQBAAAA0IIgDAAAAIAWBGEAAAAAtCAIAwAAAKAFQRgAAAAALQjCAAAAAGhBEAYAAABAC4IwAAAAAFoQhAEAAADQgiAMAAAAgBYEYQAAAAC0IAgDAAAAoAVBGAAAAAAtCMIAAAAAaEEQBgAAAEALgjAAAAAAWhCEAQAAANCCIAwAAACAFgRhAAAAALQgCAMAAACgBUEYAAAAAC0IwgAAAABoQRAGAAAAQAuCMAAAAABaEIQBAAAA0IIgDAAAAIAWBGEAAAAAtCAIAwAAAKAFQRgAAAAALQjCAAAAAGjhiEFYVV1aVbdW1XXrlv1sVd1cVddMXxesu+4nq2p/Vb27qh6+bvl507L9VbU2/6YAAAAAwMaOZkbYi5Ocd5jlzx1j3H/6uiJJqup+SR6b5Bun3/nVqjqpqk5K8itJzk9yvySPm24LAAAAANti5Ug3GGO8qapWj7LehUlePsb4lyTvr6r9Sc6Zrts/xnhfklTVy6fbvuu2rzIAAAAA3HZbOUbYJVV17bTr5CnTsnsm+eC629w0LdtoOQAAAABsiyPOCNvA85M8K8mYvv9SkifOsUJVdXGSi5PkXve61xwlAYDjwOravlnrHdi7Z9Z6AACc+I5pRtgY45YxxmfGGJ9N8uv5/O6PNyc5c91Nz5iWbbT8cLVfMMY4e4xx9mmnnXYsqwcAAAAAX+SYgrCquse6Hx+V5OAZJS9P8tiqukNV3TvJWUnemuRtSc6qqntX1e2zOKD+5ce+2gAAAABw2xxx18iqelmShyQ5tapuSvLMJA+pqvtnsWvkgST/MUnGGNdX1SuzOAj+p5M8dYzxmanOJUlen+SkJJeOMa6fe2MAAAAAYCNHc9bIxx1m8Qs3uf2zkzz7MMuvSHLFbVo7AAAAAJjJVs4aCQAAAAC7hiAMAAAAgBaOuGskAAAAAMeH1bV9s9Y7sHfPrPWOd2aEAQAAANCCIAwAAACAFgRhAAAAALQgCAMAAACgBUEYAAAAAC04ayQAAABwwnO2RRIzwgAAAABoQhAGAAAAQAuCMAAAAABaEIQBAAAA0IIgDAAAAIAWBGEAAAAAtLCy0ysAAMCJxynqAejI69/xz4wwAAAAAFoQhAEAAADQgiAMAAAAgBYEYQAAAAC0IAgDAAAAoAVBGAAAAAAtCMIAAAAAaEEQBgAAAEALgjAAAAAAWhCEAQAAANCCIAwAAACAFgRhAAAAALQgCAMAAACgBUEYAAAAAC0IwgAAAABoQRAGAAAAQAuCMAAAAABaEIQBAAAA0IIgDAAAAIAWBGEAAAAAtLCy0ysAG1ld2zdrvQN798xaDwAAANhdzAgDAAAAoAVBGAAAAAAtCMIAAAAAaEEQBgAAAEALgjAAAAAAWhCEAQAAANCCIAwAAACAFgRhAAAAALQgCAMAAACgBUEYAAAAAC0IwgAAAABoQRAGAAAAQAuCMAAAAABaEIQBAAAA0IIgDAAAAIAWBGEAAAAAtCAIAwAAAKAFQRgAAAAALQjCAAAAAGhBEAYAAABAC4IwAAAAAFoQhAEAAADQgiAMAAAAgBYEYQAAAAC0IAgDAAAAoAVBGAAAAAAtCMIAAAAAaGFlp1cA4ESzurZv1noH9u6ZtR4A7FZzvsZ6fQXoyYwwAAAAAFoQhAEAAADQgiAMAAAAgBYEYQAAAAC0IAgDAAAAoAVBGAAAAAAtCMIAAAAAaEEQBgAAAEALgjAAAAAAWhCEAQAAANCCIAwAAACAFgRhAAAAALQgCAMAAACgBUEYAAAAAC0IwgAAAABoQRAGAAAAQAuCMAAAAABaEIQBAAAA0IIgDAAAAIAWVnZ6BQC20+ravlnrHdi7Z9Z6AAAALI8ZYQAAAAC0IAgDAAAAoAVBGAAAAAAtCMIAAAAAaEEQBgAAAEALgjAAAAAAWhCEAQAAANCCIAwAAACAFgRhAAAAALQgCAMAAACgBUEYAAAAAC0IwgAAAABoQRAGAAAAQAuCMAAAAABaEIQBAAAA0IIgDAAAAIAWBGEAAAAAtCAIAwAAAKAFQRgAAAAALQjCAAAAAGhBEAYAAABAC0cMwqrq0qq6taquW7fsblV1ZVW9d/p+yrS8qup5VbW/qq6tqges+52Lptu/t6ouWs7mAAAAAMDhHc2MsBcnOe+QZWtJ3jjGOCvJG6efk+T8JGdNXxcneX6yCM6SPDPJA5Ock+SZB8MzAAAAANgORwzCxhhvSvKxQxZfmOSy6fJlSR65bvlLxsKbk5xcVfdI8vAkV44xPjbG+PskV+aLwzUAAAAAWJpjPUbY6WOMD02XP5zk9OnyPZN8cN3tbpqWbbQcAAAAALbFlg+WP8YYScYM65IkqaqLq+qqqrrqIx/5yFxlAQAAAGjuWIOwW6ZdHjN9v3VafnOSM9fd7oxp2UbLv8gY4wVjjLPHGGefdtppx7h6AAAAAPCFjjUIuzzJwTM/XpTkdeuWP346e+SDknx82oXy9UkeVlWnTAfJf9i0DAAAAAC2xcqRblBVL0vykCSnVtVNWZz9cW+SV1bVk5J8IMljpptfkeSCJPuTfDLJE5JkjPGxqnpWkrdNt/v5McahB+AHAAAAgKU5YhA2xnjcBlede5jbjiRP3aDOpUkuvU1rBwAAAAAz2fLB8gEAAABgNxCEAQAAANCCIAwAAACAFgRhAAAAALQgCAMAAACgBUEYAAAAAC0IwgAAAABoQRAGAAAAQAuCMAAAAABaEIQBAAAA0IIgDAAAAIAWBGEAAAAAtCAIAwAAAKAFQRgAAAAALQjCAAAAAGhBEAYAAABAC4IwAAAAAFoQhAEAAADQgiAMAAAAgBYEYQAAAAC0IAgDAAAAoAVBGAAAAAAtCMIAAAAAaEEQBgAAAEALgjAAAAAAWhCEAQAAANCCIAwAAACAFgRhAAAAALQgCAMAAACgBUEYAAAAAC0IwgAAAABoQRAGAAAAQAuCMAAAAABaEIQBAAAA0IIgDAAAAIAWBGEAAAAAtCAIAwAAAKAFQRgAAAAALQjCAAAAAGhBEAYAAABAC4IwAAAAAFoQhAEAAADQgiAMAAAAgBYEYQAAAAC0IAgDAAAAoIWVnV4BYOtW1/bNWu/A3j2z1gOA3cprLACcWMwIAwAAAKAFQRgAAAAALQjCAAAAAGhBEAYAAABAC4IwAAAAAFoQhAEAAADQgiAMAAAAgBYEYQAAAAC0IAgDAAAAoAVBGAAAAAAtCMIAAAAAaEEQBgAAAEALgjAAAAAAWhCEAQAAANCCIAwAAACAFgRhAAAAALQgCAMAAACgBUEYAAAAAC0IwgAAAABoQRAGAAAAQAsrO70CAADAcq2u7Zu13oG9e2atBwDbxYwwAAAAAFoQhAEAAADQgiAMAAAAgBYEYQAAAAC0IAgDAAAAoAVBGAAAAAAtCMIAAAAAaEEQBgAAAEALgjAAAAAAWhCEAQAAANCCIAwAAACAFgRhAAAAALQgCAMAAACghZWdXgFgd1hd2zdrvQN798xaDwAAAI7EjDAAAAAAWhCEAQAAANCCIAwAAACAFgRhAAAAALQgCAMAAACgBUEYAAAAAC2s7PQKAADMZXVt36z1DuzdM2s9AAB2lhlhAAAAALQgCAMAAACgBUEYAAAAAC0IwgAAAABoQRAGAAAAQAuCMAAAAABaEIQBAAAA0IIgDAAAAIAWBGEAAAAAtCAIAwAAAKAFQRgAAAAALQjCAAAAAGhBEAYAAABACys7vQIAAHze6tq+Wesd2Ltn1noAALuZGWEAAAAAtCAIAwAAAKAFQRgAAAAALQjCAAAAAGhhS0FYVR2oqndW1TVVddW07G5VdWVVvXf6fsq0vKrqeVW1v6quraoHzLEBAAAAAHA05jhr5PeMMT667ue1JG8cY+ytqrXp559Icn6Ss6avByZ5/vQdANiEswgCAMA8lrFr5IVJLpsuX5bkkeuWv2QsvDnJyVV1jyX0BwAAAIAvstUgbCR5Q1VdXVUXT8tOH2N8aLr84SSnT5fvmeSD6373pmkZAAAAACzdVneNfPAY4+aqunuSK6vqxvVXjjFGVY3bUnAK1C5Oknvd615bXD0AAAAAWNjSjLAxxs3T91uTvCbJOUluObjL4/T91unmNyc5c92vnzEtO7TmC8YYZ48xzj7ttNO2snoAAAAA8DnHHIRV1Z2r6i4HLyd5WJLrklye5KLpZhcled10+fIkj5/OHvmgJB9ftwslAAAAACzVVnaNPD3Ja6rqYJ3fHmP8YVW9Lckrq+pJST6Q5DHT7a9IckGS/Uk+meQJW+gNAAAAALfJMQdhY4z3Jfnmwyz/uyTnHmb5SPLUY+0HAAAAAFux1bNGAgAAAMCuIAgDAAAAoAVBGAAAAAAtCMIAAAAAaEEQBgAAAEALgjAAAAAAWljZ6RUAAIBjsbq2b9Z6B/bumbUeAHD8MSMMAAAAgBYEYQAAAAC0IAgDAAAAoAVBGAAAAAAtCMIAAAAAaEEQBgAAAEALKzu9AgAHra7tm7Xegb17Zq0HAGzM6ziwFcYQtosZYQAAAAC0IAgDAAAAoAVBGAAAAAAtCMIAAAAAaEEQBgAAAEALgjAAAAAAWljZ6RUAgN3Mqb4BThzGdIATnxlhAAAAALQgCAMAAACgBUEYAAAAAC0IwgAAAABoQRAGAAAAQAuCMAAAAABaWNnpFQCgJ6eoBwB2mvcj0I8ZYQAAAAC0IAgDAAAAoAVBGAAAAAAtCMIAAAAAaEEQBgAAAEALgjAAAAAAWljZ6RUAgGVxSnQAAGA9M8IAAAAAaEEQBgAAAEALgjAAAAAAWhCEAQAAANCCIAwAAACAFgRhAAAAALSwstMrAAAAwO6yurZv1noH9u6ZtR7ARswIAwAAAKAFQRgAAAAALQjCAAAAAGhBEAYAAABAC4IwAAAAAFoQhAEAAADQwspOrwAAsPNW1/bNWu/A3j2z1mNe7m8AoCszwgAAAABoQRAGAAAAQAuCMAAAAABaEIQBAAAA0IIgDAAAAIAWBGEAAAAAtLCy0ysAALCbrK7tm63Wgb17ZqvF7jXnYyrxuILjzXY8x40jcPTMCAMAAACgBUEYAAAAAC0IwgAAAABoQRAGAAAAQAuCMAAAAABacNbIHeCMHsBWGEMAYPfyOg6ws8wIAwAAAKAFQRgAAAAALQjCAAAAAGhBEAYAAABAC4IwAAAAAFoQhAEAAADQgiAMAAAAgBYEYQAAAAC0IAgDAAAAoAVBGAAAAAAtCMIAAAAAaEEQBgAAAEALgjAAAAAAWhCEAQAAANCCIAwAAACAFgRhAAAAALQgCAMAAACgBUEYAAAAAC0IwgAAAABoQRAGAAAAQAuCMAAAAABaEIQBAAAA0IIgDAAAAIAWBGEAAAAAtCAIAwAAAKAFQRgAAAAALQjCAAAAAGhBEAYAAABAC4IwAAAAAFoQhAEAAADQgiAMAAAAgBYEYQAAAAC0IAgDAAAAoAVBGAAAAAAtCMIAAAAAaEEQBgAAAEALgjAAAAAAWhCEAQAAANCCIAwAAACAFgRhAAAAALQgCAMAAACgBUEYAAAAAC0IwgAAAABoQRAGAAAAQAvbHoRV1XlV9e6q2l9Va9vdHwAAAICetjUIq6qTkvxKkvOT3C/J46rqftu5DgAAAAD0tN0zws5Jsn+M8b4xxqeSvDzJhdu8DgAAAAA0tN1B2D2TfHDdzzdNywAAAABgqWqMsX3Nqh6d5LwxxpOnn384yQPHGJesu83FSS6efrxvkndv2woef05N8tFd3uNE2AY99NitPU6EbdBDj93a40TYBj302K09ToRt0EOP3drjRNgGPU4MXz3GOO1wV6xs84rcnOTMdT+fMS37nDHGC5K8YDtX6nhVVVeNMc7ezT1OhG3QQ4/d2uNE2AY99NitPU6EbdBDj93a40TYBj302K09ToRt0OPEt927Rr4tyVlVde+qun2Sxya5fJvXAQAAAICGtnVG2Bjj01V1SZLXJzkpyaVjjOu3cx0AAAAA6Gm7d43MGOOKJFdsd99dajt2EV12jxNhG/TQY7f2OBG2QQ89dmuPE2Eb9NBjt/Y4EbZBDz12a48TYRv0OMFt68HyAQAAAGCnbPcxwgAAAABgRwjCjkNVdV5Vvbuq9lfV2hLqX1pVt1bVdcuuW1V3q6orq+q90/dTltDjB6rq+qr6bFVt+YwYG/R4TlXdWFXXVtVrqurkJfR41lT/mqp6Q1V91dw91l3341U1qurUuXtU1c9W1c3TdlxTVRfM3WNa/p+n++T6qvrFmbfhFevW/0BVXbOFTdiox/2r6s1Tj6uq6pwl9PjmqvrLqnpnVf1eVX35Vnoc0u/MqvqTqnrXdB88bZl15xpLNqk/2ziySY/ZxpFNesw2jhzpPp5jHNlkO2YbRzbbjhnHkY22Y7axZJMes40lm/RYylhSVV9aVW+tqndM/X5umXVrcbKmt9Ti/dUranHipjnrXzLVnuP1daMeL63Fe8TrajHu324JPV44Lbu2qn63qr5s7h7rrn9eVf3TsdY/wna8uKrev+45eP8l9KiqenZVvaeqbqiqH1tCjz9ftw1/W1WvXUKPc6vq7VOPv6iqr5u5/kOn+tdV1WVVNevhearqpKr6q6r6/WXWnWsMOUKP2caRTXrMNo4cpteBWrxWXFNVV81V95AeJ09j043T8+7bZ65/33XPuWuq6hNV9fQ5e0x9njE9T66rqpdV1ZfOXP9pU+3rl7H+u94Yw9dx9JXFSQT+OsnXJLl9knckud/MPb4ryQOSXLfsukl+McnadHktyS8socc3JLlvkj9NcvaStuNhSVamy7+wpO348nWXfyzJry3jfk5yZhYnrPhAklOXsB0/m+S/Lvlx9T1J/ijJHaaf7z7332nd9b+U5GeWsA1vSHL+dPmCJH+6hB5vS/Ld0+UnJnnWjPfLPZI8YLp8lyTvmWOs2qjuXGPJJvVnG0c26THbOLJJj9nGkc3u47nGkU22Y7ZxZJMec44jR3w+bHUs2WQ7ZhtLNumxlLEkSSX5suny7ZK8JcmDllU3ySuTPHZa/mtJnjJz/W9JsprkwFaeF0foccF0XSV52bFuwxF6rB9HfjnT2Dv3fZzk7CS/meSflvS3enGSRy/zsZrkCUlekuRLpuu2Mo4c8fmQ5FVJHr+E7XhPkm+Ylv9okhfPWP/fJvlgkvtMy38+yZPmuF/W9f0vSX47ye8vs+5cY8gResw2jmzSY7Zx5DC9ZlvvTXpcluTJ0+XbJzl5ib1OSvLhJF89c917Jnl/kjuue2z9yIz1vynJdUnulMVx4f8oydct837ZbV9mhB1/zkmyf4zxvjHGp5K8PMmFczYYY7wpycfmrLlJ3QuzGKwyfX/k3D3GGDeMMd69lbpH0eMNY4xPTz++OckZS+jxiXU/3jnJlg7gt8n9/Nwk/32r9Y/QYzYb9HhKkr1jjH+ZbnPrzPWTLD7pTfKYLN4kHLMNeowkB2dV3DXJ3y6hx32SvGm6fGWSf7+VHof0+9AY4+3T5X9MckMWL+rLqjvLWLJR/TnHkU16zDaObNJjtnHkCPfxLOPIsh5HR9ljznFk0+2YYyzZpMdsY8kmPZYyloyFg7OBbjd9zfHatFHdhyb53Wn5VsaRw9YfY/zVGOPAsa73Ufa4YrpuJHlrtjaObNTjE8nnHrd3zNbGkcP2qKqTkjwni3FkS5b1ODrKHk9J8vNjjM9Ot9vKOLLpdtRiJuZDk7x2CT1mGUc2qP+ZJJ8aY7xnWj7r+5GqOiPJniS/MVfNw9Wdng+zjCEb9UiSOceRTXrMNo5st6q6axYf/r4wScYYnxpj/MMSW56b5K/HGB9YQu2VJHecZkjeKVv8X+AQ35DkLWOMT07vPf8syffPWH/XE4Qdf+6ZxacmB92Umf8p2GanjzE+NF3+cJLTd3JlZvLEJH+wjMLT9PoPJvmhJD+zhPoXJrl5jPGOuWsf4pJa7FJxaW1xd9gN3CfJd07T0/+sqr5tCT2S5DuT3DLGeO8Saj89yXOm+/t/JvnJJfS4Pp8P0n8gi1k8s6uq1Sw+wXzLEuvOPpYsa72Pssds48ihPZYxjqzvsaxx5DB/q9nHkUN6LGUc2eA+n3UsOaTH07OEseSQHksbS6Zddq5JcmuSK8cYszwfD62bxWz7f1gXRm/p/dWy1vtoe0y7Mv1wkj9cRo+qelEWY+3XJ/k/S+hxSZLL143rW7LJ3+rZ0zjy3Kq6wxJ6fG2SH6zFbsl/UFVnLaHHQY9M8sZDPvCYq8eTk1xRVTdl8bjaO1f9LIKWlfr8YQcenXnfj/yvLALVz85Y83B1vyIzjiEb9FiGDXvMNY4cYiR5Q1VdXVUXz1j3oHsn+UiSF027e/5GVd15CX0Oemy2+IH44Ywxbs7iNftvknwoycfHGG+YscV1WbzH+YqqulMWswCX8n/AbiUIY9tMnzrM+gnddquqn07y6SQvXUb9McZPjzHOnOpfMmftaRD8qSwhYDvE87N4Y3j/LAb2X1pCj5Ukd8tiOv9/S/LK6ZO6uT0uS3jxmzwlyTOm+/sZmT7ZmtkTk/xoVV2dxW5On5q7QS2OHfOqJE/f6pvzo607x1iyrPU+mh5zjiOH6zH3OLK+RxbrPfs4cpjtmH0cOUyP2ceRTR5Xs40lh+kx+1hymB5LG0vGGJ8ZY9w/ixkJ51TVNy2jbhaBzmyWtd63ocevJnnTGOPPl9FjjPGEJF+VxazAH5y5x3dlEahuKWA7Qo9vyiIU/vok35bFc/0nltDjDkn+eYxxdpJfT3LpEnocNMs4skGPZyS5YIxxRpIXZbFL7Cz1k3xjFmHCc6vqrUn+MYtZYltWVd+X5NYxxtVz1Ft23eOwxyzjyCEePMZ4QJLzkzx1er7PaSWLQ4E8f4zxLUn+XxaHzJhdLY4B94gkv7OE2qdk8QHTvbMYa+9cVf9hrvpjjBuyOAzHG7IIOq/JTM+7E4Ug7Phzc74wrT1jWrZb3VJV90iS6fsxTxnfaVX1I0m+L8kPTf+IL9NLM+O08cnXZjHYvqOqDmTx2Hp7VX3lnE3GGLdMb4I+m8Wbwi0dBH4DNyV59TSr+61ZfMo1ywFFD5qmKX9/klfMWXedi5K8err8O1nC32mMceMY42FjjG/N4s3zX89Zf/ok8VVJXjrGePWRbr/FurONJcta76PpMec4chTbseVx5DA9Zh9HDrcdc48jG/ytZh1HNrnPZxtLNugx61iywf2x1LFk6vEPSf4kyXlLqvvtSU6uzx+ke5b3V8ta7816VNUzk5yWxXF/ltJjWvaZLA7RMdeusAd7fE+Sr0uyfxpH7lRV+2fucd5Y7Oo7xmL35xdlptfZQ/5WN+Xzz7/XJPk3S+iRWhw0/Zwk++aof0iP85N887rZZ6/I4rhec9U/b4zxl2OM7xxjnJPFbtbv2fSXj953JHnE9Dh6eZKHVtVvLaNukv+deceQZa37UfVYxjiSfG6m08HdhF+T+d/f3pTkpnWP19/NIhhbhvOTvH2MccsSan9vkvePMT4yxvjXLMaRLT/v1htjvHCM8a1jjO9K8veZ73l3QhCEHX/eluSsWpyV5PZZfIJy+Q6v01ZcnsWb9EzfX7eD63LMquq8LKYVP2KM8ckl9Vg/nf7CJDfOWX+M8c4xxt3HGKtjjNUsXkgeMMb48Jx9DoYVk0dlMTV3bq/N4o10quo+WRwo86Mz9/jeJDeOMW6aue5Bf5vku6fLD00y++6XVXX36fuXJPkfWRzYda7alcXMkxvGGMf8yfFtqDvLWLKs9T6aHnOOI5v0mG0cOVyPuceRTbZjtnFkk/v8tZlpHDnC42qWsWSTHrONJZvcH0sZS6rqtJrOnlpVd0zy7zLDa98GdW/I4p/yR08328o4spT1PpoeVfXkJA9P8rgpKJ67x7trOmPg9Hh4RLY2jhyux9VjjK9cN458coxxTGcp3KTHjes+PKksdivcyjiy0X3+2kzjSBbPw2P+R/MIj6tHZ3Gg838+1vqb9LghyV2ncTDrls1V/8Z1Y8gdspiZN8sYMsb4yTHGGdPj6LFJ/niMseVZNRvU/aHMNIZs0mO2GUGb9ZhzHFmvqu5cVXc5eDmLkwTN+n/A9H7jg1V132nRuUneNWePdZa5Z8jfJHlQVd1pGqPOzTE+7zay7nl3ryw+kPvtOevveuM4OGK/ry/8ymIf3vdk8YnrTy+h/suy2NXkX7P4J2aWM7ccrm4W+9O/MYs35n+U5G5L6PGo6fK/JLklyeuX0GN/Fsduu2b62uoZHQ/X41VZvFhcm+T3sjjw9dLu58xzVqvDbcdvJnnntB2XJ7nHEnrcPslvTX+vtyd56Nx/pyzONvWflvjceHCSq7M4M+xbknzrEno8bRpL3pPF8T5qju2Z+j04i90Tr133vLhgWXXnGks2qT/bOLJJj9nGkU16zDaOHM19nC2OI5tsx2zjyCY95hxHNvxbZaaxZJPtmG0s2aTHUsaSLGbP/NXU77ps8Qy9R6qbxRm53zo9F38n0xlDZ6z/Y1mMI5/OIqD8jSVsw6ezeH948P7ZyplIv6hHFh+S/9/p+XddFjNLv3zu7TjkNls9a+RGf6s/Xrcdv5XpbIYz9zg5i1la70zyl1nMrJr9b5XFGY3PW+Jz41HTNrxj6vU1M9d/Thb/5L87i12ut7QdG/R+SGY+a+ShdecaQ47QY7ZxZJMes40jh/T4mukx9I4sji05+/+xU5/7J7lqepy9NskpS+hx5yR/l+Suy9iGqcfPZRF2X5fF+55ZHk/r6v95FiHhO5Kcu6zt2K1fNf2RAAAAAOCEZtdIAAAAAFoQhAEAAADQgiAMAAAAgBYEYQAAAAC0IAgDAAAAoAVBGAAAAAAtCMIAAAAAaEEQBgAAAEAL/x8IaX9EGGY2awAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1512x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's see how many images are there per classes\n",
    "folders = os.listdir(train_path)\n",
    "#class_num:no.of samples\n",
    "samples_dict = {} \n",
    "\n",
    "for folder in folders:\n",
    "    images_in_folder = os.listdir(train_path + '/' + folder)\n",
    "    samples_dict[folder] = len(images_in_folder)\n",
    "    \n",
    "plt.figure(figsize=(21,10))  \n",
    "plt.bar(*zip(*samples_dict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "361327de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T16:27:20.462664Z",
     "iopub.status.busy": "2023-01-09T16:27:20.460980Z",
     "iopub.status.idle": "2023-01-09T16:27:20.665566Z",
     "shell.execute_reply": "2023-01-09T16:27:20.662766Z"
    },
    "papermill": {
     "duration": 0.21429,
     "end_time": "2023-01-09T16:27:20.669882",
     "exception": false,
     "start_time": "2023-01-09T16:27:20.455592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Checking for physical Tensorflow devices\n",
      ": /physical_device:CPU:0\n",
      ": /physical_device:XLA_CPU:0\n",
      ": /physical_device:GPU:0\n",
      ": /physical_device:XLA_GPU:0\n"
     ]
    }
   ],
   "source": [
    "print(\"--> Checking for physical Tensorflow devices\")\n",
    "for device in tf.config.list_physical_devices():\n",
    "    print(\": {}\".format(device.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbbd5c1",
   "metadata": {
    "papermill": {
     "duration": 0.004345,
     "end_time": "2023-01-09T16:27:20.679364",
     "exception": false,
     "start_time": "2023-01-09T16:27:20.675019",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Processing the training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f113befd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T16:27:20.690264Z",
     "iopub.status.busy": "2023-01-09T16:27:20.689370Z",
     "iopub.status.idle": "2023-01-09T16:32:18.363862Z",
     "shell.execute_reply": "2023-01-09T16:32:18.362534Z"
    },
    "papermill": {
     "duration": 297.686258,
     "end_time": "2023-01-09T16:32:18.369711",
     "exception": false,
     "start_time": "2023-01-09T16:27:20.683453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39209, 30, 30, 3) (39209,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    image_data = []\n",
    "    image_labels = []\n",
    "    class_num = len(os.listdir(train_path))\n",
    "    for i in range(class_num):\n",
    "        path = train_path +'/'+ str(i)\n",
    "        images = os.listdir(path)\n",
    "\n",
    "        for img in images:\n",
    "            try:\n",
    "                    \n",
    "                #print(path+'/'+img)\n",
    "                    image = cv2.imread(path + '/' + img)\n",
    "                    image_fromarray = Image.fromarray(image, 'RGB')\n",
    "                    resize_image = image_fromarray.resize((30, 30))\n",
    "                    image_data.append(np.array(resize_image))\n",
    "                    image_labels.append(i)\n",
    "            except:\n",
    "                print(\"Error in \" + img)\n",
    "\n",
    "image_data = np.array(image_data)\n",
    "image_labels = np.array(image_labels)\n",
    "print(image_data.shape, image_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0151d8ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T16:32:18.385285Z",
     "iopub.status.busy": "2023-01-09T16:32:18.384843Z",
     "iopub.status.idle": "2023-01-09T16:32:19.595934Z",
     "shell.execute_reply": "2023-01-09T16:32:19.594852Z"
    },
    "papermill": {
     "duration": 1.220755,
     "end_time": "2023-01-09T16:32:19.598804",
     "exception": false,
     "start_time": "2023-01-09T16:32:18.378049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (31367, 30, 30, 3)\n",
      "X_valid.shape (7842, 30, 30, 3)\n",
      "y_train.shape (31367, 43)\n",
      "y_valid.shape (7842, 43)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(image_data, image_labels, test_size=0.2, random_state=42, shuffle=True)\n",
    "X_train = X_train/255 \n",
    "X_val = X_val/255\n",
    "\n",
    "y_train = to_categorical(y_train, class_num)\n",
    "y_val = to_categorical(y_val, class_num)\n",
    "\n",
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(\"X_valid.shape\", X_val.shape)\n",
    "print(\"y_train.shape\", y_train.shape)\n",
    "print(\"y_valid.shape\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cade7b14",
   "metadata": {
    "papermill": {
     "duration": 0.004567,
     "end_time": "2023-01-09T16:32:19.608266",
     "exception": false,
     "start_time": "2023-01-09T16:32:19.603699",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b32870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Convolution2D(16, 3, 3, input_shape = (30, 30, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Convolution2D(16, 3, 3, activation = 'relu'))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(256, activation = 'relu'))\n",
    "classifier.add(Dense(43, activation = 'softmax'))\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d037f554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1961/1961 - 6s - loss: 2.2400 - accuracy: 0.3559 - val_loss: 1.5904 - val_accuracy: 0.5080\n",
      "Epoch 2/10\n",
      "1961/1961 - 6s - loss: 1.3618 - accuracy: 0.5774 - val_loss: 1.2209 - val_accuracy: 0.6317\n",
      "Epoch 3/10\n",
      "1961/1961 - 6s - loss: 1.1443 - accuracy: 0.6440 - val_loss: 1.0781 - val_accuracy: 0.6678\n",
      "Epoch 4/10\n",
      "1961/1961 - 6s - loss: 1.0085 - accuracy: 0.6843 - val_loss: 0.9987 - val_accuracy: 0.6771\n",
      "Epoch 5/10\n",
      "1961/1961 - 6s - loss: 0.9106 - accuracy: 0.7135 - val_loss: 0.9222 - val_accuracy: 0.7061\n",
      "Epoch 6/10\n",
      "1961/1961 - 6s - loss: 0.8394 - accuracy: 0.7355 - val_loss: 0.8572 - val_accuracy: 0.7257\n",
      "Epoch 7/10\n",
      "1961/1961 - 6s - loss: 0.7810 - accuracy: 0.7517 - val_loss: 0.8825 - val_accuracy: 0.7313\n",
      "Epoch 8/10\n",
      "1961/1961 - 6s - loss: 0.7365 - accuracy: 0.7660 - val_loss: 0.7630 - val_accuracy: 0.7580\n",
      "Epoch 9/10\n",
      "1961/1961 - 6s - loss: 0.6950 - accuracy: 0.7807 - val_loss: 0.7252 - val_accuracy: 0.7716\n",
      "Epoch 10/10\n",
      "1961/1961 - 6s - loss: 0.6595 - accuracy: 0.7909 - val_loss: 0.7515 - val_accuracy: 0.7613\n"
     ]
    }
   ],
   "source": [
    "hist = classifier.fit(X_train, y_train, batch_size=16, epochs=10, shuffle=True, verbose=2, validation_data=(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d4ea8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('rcnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bdd9ab",
   "metadata": {},
   "source": [
    "# LSTM + CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52d7c111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39209, 30, 30, 3) (39209,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    image_data = []\n",
    "    image_labels = []\n",
    "    class_num = len(os.listdir(train_path))\n",
    "    for i in range(class_num):\n",
    "        path = train_path +'/'+ str(i)\n",
    "        images = os.listdir(path)\n",
    "\n",
    "        for img in images:\n",
    "            try:\n",
    "                    \n",
    "                #print(path+'/'+img)\n",
    "                    image = cv2.imread(path + '/' + img)\n",
    "                    image_fromarray = Image.fromarray(image, 'RGB')\n",
    "                    resize_image = image_fromarray.resize((30, 30))\n",
    "                    image_data.append(np.array(resize_image))\n",
    "                    image_labels.append(i)\n",
    "            except:\n",
    "                print(\"Error in \" + img)\n",
    "\n",
    "image_data = np.array(image_data)\n",
    "image_labels = np.array(image_labels)\n",
    "print(image_data.shape, image_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60138d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_train, y_val = train_test_split(image_data, image_labels, test_size=0.2, random_state=42, shuffle=True)\n",
    "X_train = X_train/255 \n",
    "X_val = X_val/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27aed189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7842,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f10e80c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31367, 30, 30, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e2b9806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "#from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout,LSTM\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import TimeDistributed, Conv2D, MaxPooling2D, Flatten, Dropout, Dense,LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "695e394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "       featurewise_center=False,  \n",
    "       samplewise_center=False,  \n",
    "       featurewise_std_normalization=False,  \n",
    "       samplewise_std_normalization=False,  \n",
    "       zca_whitening=False,  \n",
    "       rotation_range = 90, \n",
    "       zoom_range = 0.5, \n",
    "       width_shift_range=0.2,  \n",
    "       height_shift_range=0.2,  \n",
    "       horizontal_flip = True,  \n",
    "       \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82796967",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(X_train)\n",
    "datagen.fit(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51f00bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(X_train).reshape(31367,1,30,30, 3)\n",
    "x_test = np.array(X_val).reshape(7842,1,30,30, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d24fef57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (31367, 1, 30, 30, 3)\n",
      "y_train: (31367,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train:\",x_train.shape)\n",
    "print(\"y_train:\",y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60928417",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv2D(64,(3,3),activation='relu'),input_shape=(1,30,30,3)))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(32,(3,3),activation='relu')))\n",
    "#model_mix_shoulder.add(TimeDistributed(Conv2D(128,(3,3),activation='relu')))\n",
    "#model_mix_shoulder.add(TimeDistributed(Conv2D(56,(3,3),activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2))))\n",
    "\n",
    "#model_mix_shoulder.add(TimeDistributed(Conv2D(256,(3,3),activation='relu')))\n",
    "#model_mix_shoulder.add(TimeDistributed(MaxPooling2D(pool_size=(2,2))))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "#RNN\n",
    "model.add(LSTM(100,return_sequences=False))\n",
    "\n",
    "model.add(Dense(2,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1ebcbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a7f6b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "981/981 [==============================] - 25s 25ms/step - loss: nan - accuracy: 0.0055 - val_loss: nan - val_accuracy: 0.0048\n",
      "Epoch 2/25\n",
      "981/981 [==============================] - 24s 24ms/step - loss: nan - accuracy: 0.0055 - val_loss: nan - val_accuracy: 0.0048\n",
      "Epoch 3/25\n",
      "981/981 [==============================] - 24s 24ms/step - loss: nan - accuracy: 0.0055 - val_loss: nan - val_accuracy: 0.0048\n",
      "Epoch 4/25\n",
      "981/981 [==============================] - 24s 24ms/step - loss: nan - accuracy: 0.0055 - val_loss: nan - val_accuracy: 0.0048\n",
      "Epoch 5/25\n",
      "981/981 [==============================] - 24s 24ms/step - loss: nan - accuracy: 0.0055 - val_loss: nan - val_accuracy: 0.0048\n",
      "Epoch 6/25\n",
      "981/981 [==============================] - 24s 24ms/step - loss: nan - accuracy: 0.0055 - val_loss: nan - val_accuracy: 0.0048\n",
      "Epoch 7/25\n",
      "981/981 [==============================] - 24s 24ms/step - loss: nan - accuracy: 0.0055 - val_loss: nan - val_accuracy: 0.0048\n",
      "Epoch 8/25\n",
      "981/981 [==============================] - 24s 24ms/step - loss: nan - accuracy: 0.0055 - val_loss: nan - val_accuracy: 0.0048\n",
      "Epoch 9/25\n",
      "981/981 [==============================] - 24s 24ms/step - loss: nan - accuracy: 0.0055 - val_loss: nan - val_accuracy: 0.0048\n",
      "Epoch 10/25\n",
      "981/981 [==============================] - 24s 24ms/step - loss: nan - accuracy: 0.0055 - val_loss: nan - val_accuracy: 0.0048\n",
      "Epoch 11/25\n",
      "981/981 [==============================] - 24s 25ms/step - loss: nan - accuracy: 0.0055 - val_loss: nan - val_accuracy: 0.0048\n",
      "Epoch 12/25\n",
      "981/981 [==============================] - 24s 24ms/step - loss: nan - accuracy: 0.0055 - val_loss: nan - val_accuracy: 0.0048\n",
      "Epoch 13/25\n",
      "981/981 [==============================] - 24s 24ms/step - loss: nan - accuracy: 0.0055 - val_loss: nan - val_accuracy: 0.0048\n",
      "Epoch 14/25\n",
      "981/981 [==============================] - 24s 24ms/step - loss: nan - accuracy: 0.0055 - val_loss: nan - val_accuracy: 0.0048\n",
      "Epoch 15/25\n",
      "981/981 [==============================] - 24s 24ms/step - loss: nan - accuracy: 0.0055 - val_loss: nan - val_accuracy: 0.0048\n",
      "Epoch 16/25\n",
      "981/981 [==============================] - 24s 24ms/step - loss: nan - accuracy: 0.0055 - val_loss: nan - val_accuracy: 0.0048\n",
      "Epoch 17/25\n",
      "981/981 [==============================] - 24s 24ms/step - loss: nan - accuracy: 0.0055 - val_loss: nan - val_accuracy: 0.0048\n",
      "Epoch 18/25\n",
      "981/981 [==============================] - 24s 24ms/step - loss: nan - accuracy: 0.0055 - val_loss: nan - val_accuracy: 0.0048\n",
      "Epoch 19/25\n",
      "981/981 [==============================] - 24s 24ms/step - loss: nan - accuracy: 0.0055 - val_loss: nan - val_accuracy: 0.0048\n",
      "Epoch 20/25\n",
      "981/981 [==============================] - 24s 24ms/step - loss: nan - accuracy: 0.0055 - val_loss: nan - val_accuracy: 0.0048\n",
      "Epoch 21/25\n",
      "981/981 [==============================] - 24s 24ms/step - loss: nan - accuracy: 0.0055 - val_loss: nan - val_accuracy: 0.0048\n",
      "Epoch 22/25\n",
      "981/981 [==============================] - 24s 24ms/step - loss: nan - accuracy: 0.0055 - val_loss: nan - val_accuracy: 0.0048\n",
      "Epoch 23/25\n",
      "981/981 [==============================] - 24s 24ms/step - loss: nan - accuracy: 0.0055 - val_loss: nan - val_accuracy: 0.0048\n",
      "Epoch 24/25\n",
      "981/981 [==============================] - 24s 24ms/step - loss: nan - accuracy: 0.0055 - val_loss: nan - val_accuracy: 0.0048\n",
      "Epoch 25/25\n",
      "981/981 [==============================] - 24s 24ms/step - loss: nan - accuracy: 0.0055 - val_loss: nan - val_accuracy: 0.0048\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,epochs = 25,validation_data = (x_test,y_val),shuffle=True,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1405ccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cnn-lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8117595c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14655.389371,
   "end_time": "2023-01-09T20:31:10.313056",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-01-09T16:26:54.923685",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
